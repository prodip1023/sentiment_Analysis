{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All required commands to install MLflow on EC2:\n",
    "\n",
    "https://github.com/entbappy/MLflow-Basic-Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow-Basic-Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Dagshub:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MLFLOW_TRACKING_URI=https://dagshub.com/entbappy/MLflow-Basic-Demo.mlflow\n",
    "- MLFLOW_TRACKING_USERNAME=entbappy\n",
    "- MLFLOW_TRACKING_PASSWORD=6824692c47a369aa6f9eac5b10041d5c8edbcef0\n",
    "- python script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "export MLFLOW_TRACKING_URI=https://dagshub.com/prodip/MLflow-Basic-Demo.mlflow\n",
    "\n",
    "export MLFLOW_TRACKING_USERNAME=prodip \n",
    "\n",
    "export MLFLOW_TRACKING_PASSWORD=6824692c47a369aa6f9eac5b10041d5c8edbcef0\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow on AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLflow on AWS Setup:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Login to AWS console.\n",
    "2. Create IAM user with AdministratorAccess\n",
    "3. Export the credentials in your AWS CLI by running \"aws configure\"\n",
    "4. Create a s3 bucket\n",
    "5. Create EC2 machine (Ubuntu) & add Security groups 5000 port"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the following command on EC2 machine\n",
    "\n",
    "```\n",
    "sudo apt update\n",
    "\n",
    "sudo apt install python3-pip\n",
    "\n",
    "sudo apt install pipenv\n",
    "\n",
    "sudo apt install virtualenv\n",
    "\n",
    "mkdir mlflow\n",
    "\n",
    "cd mlflow\n",
    "\n",
    "pipenv install mlflow\n",
    "\n",
    "pipenv install awscli\n",
    "\n",
    "pipenv install boto3\n",
    "\n",
    "pipenv shell\n",
    "\n",
    "\n",
    "## Then set aws credentials\n",
    "aws configure\n",
    "\n",
    "\n",
    "#Finally mlflow-test-23 is your bucket name\n",
    "mlflow server -h 0.0.0.0 --default-artifact-root s3://mlflow-test-23\n",
    "\n",
    "#open Public IPv4 DNS to the port 5000\n",
    "\n",
    "\n",
    "#set uri in your local terminal and in your code \n",
    "export MLFLOW_TRACKING_URI=http://ec2-54-147-36-34.compute-1.amazonaws.com:5000/\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test mlflow\n",
    "\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://ec2-54-234-87-231.compute-1.amazonaws.com:5000/\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"param1\", 15)\n",
    "    mlflow.log_metric(\"metric1\", 0.89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating baseline model\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon have never tried explain them t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buddhism has very much lot compatible with chr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously don say thing first all they won get...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what you have learned yours and only yours wha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for your own benefit you may want read living ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean_comment  category\n",
       "0   family mormon have never tried explain them t...         1\n",
       "1  buddhism has very much lot compatible with chr...         1\n",
       "2  seriously don say thing first all they won get...        -1\n",
       "3  what you have learned yours and only yours wha...         0\n",
       "4  for your own benefit you may want read living ...         1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/Himanshu-1703/reddit-sentiment-analysis/refs/heads/main/data/reddit.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df['clean_comment'].str.strip() == '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure necessary NLTK data is downloaded\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the preprocessing function\n",
    "def preprocess_comment(comment):\n",
    "    # Convert to lowercase\n",
    "    comment = comment.lower()\n",
    "\n",
    "    # Remove trailing and leading whitespaces\n",
    "    comment = comment.strip()\n",
    "\n",
    "    # Remove newline characters\n",
    "    comment = re.sub(r'\\n', ' ', comment)\n",
    "\n",
    "    # Remove non-alphanumeric characters, except punctuation\n",
    "    comment = re.sub(r'[^A-Za-z0-9\\s!?.,]', '', comment)\n",
    "\n",
    "    # Remove stopwords but retain important ones for sentiment analysis\n",
    "    stop_words = set(stopwords.words('english')) - {'not', 'but', 'however', 'no', 'yet'}\n",
    "    comment = ' '.join([word for word in comment.split() if word not in stop_words])\n",
    "\n",
    "    # Lemmatize the words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    comment = ' '.join([lemmatizer.lemmatize(word) for word in comment.split()])\n",
    "\n",
    "    return comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the preprocessing function to the 'clean_comment' column\n",
    "df['clean_comment'] = df['clean_comment'].apply(preprocess_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon never tried explain still stare ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buddhism much lot compatible christianity espe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously say thing first get complex explain ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>learned want teach different focus goal not wr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>benefit may want read living buddha living chr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean_comment  category\n",
       "0  family mormon never tried explain still stare ...         1\n",
       "1  buddhism much lot compatible christianity espe...         1\n",
       "2  seriously say thing first get complex explain ...        -1\n",
       "3  learned want teach different focus goal not wr...         0\n",
       "4  benefit may want read living buddha living chr...         1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Vectorize the comments using Bag of Words (CountVectorizer)\n",
    "vectorizer = CountVectorizer(max_features=10000)  # Bag of Words model with a limit of 1000 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(df['clean_comment']).toarray()\n",
    "y = df['category']  # Assuming 'sentiment' is the target variable (0 or 1 for binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36793, 10000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2       -1\n",
       "3        0\n",
       "4        1\n",
       "        ..\n",
       "37244    0\n",
       "37245    1\n",
       "37246    0\n",
       "37247    1\n",
       "37248    0\n",
       "Name: category, Length: 36793, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36793,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Set up the MLflow tracking server\n",
    "mlflow.set_tracking_uri(\"http://ec2-54-234-87-231.compute-1.amazonaws.com:5000/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set or create an experiment\n",
    "mlflow.set_experiment(\"Ex-1: RF Baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Step 2: Define and train a Random Forest baseline model using a simple train-test split\n",
    "with mlflow.start_run() as run:\n",
    "    # Log a description for the run\n",
    "    mlflow.set_tag(\"mlflow.runName\", \"RandomForest_Baseline_TrainTestSplit\")\n",
    "    mlflow.set_tag(\"experiment_type\", \"baseline\")\n",
    "    mlflow.set_tag(\"model_type\", \"RandomForestClassifier\")\n",
    "\n",
    "    # Add a description\n",
    "    mlflow.set_tag(\"description\", \"Baseline RandomForest model for sentiment analysis using Bag of Words (BoW) with a simple train-test split\")\n",
    "\n",
    "    # Log parameters for the vectorizer\n",
    "    mlflow.log_param(\"vectorizer_type\", \"CountVectorizer\")\n",
    "    mlflow.log_param(\"vectorizer_max_features\", vectorizer.max_features)\n",
    "\n",
    "    # Log Random Forest parameters\n",
    "    n_estimators = 200\n",
    "    max_depth = 15\n",
    "\n",
    "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "    mlflow.log_param(\"max_depth\", max_depth)\n",
    "\n",
    "    # Initialize and train the model\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Log metrics for each class and accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    for label, metrics in classification_rep.items():\n",
    "        if isinstance(metrics, dict):  # For precision, recall, f1-score, etc.\n",
    "            for metric, value in metrics.items():\n",
    "                mlflow.log_metric(f\"{label}_{metric}\", value)\n",
    "\n",
    "    # Confusion matrix plot\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "\n",
    "    # Save and log the confusion matrix plot\n",
    "    plt.savefig(\"confusion_matrix.png\")\n",
    "    mlflow.log_artifact(\"/content/confusion_matrix.png\")\n",
    "\n",
    "    # Log the Random Forest model\n",
    "    mlflow.sklearn.log_model(model, \"random_forest_model\")\n",
    "\n",
    "    # Optionally log the dataset itself (if it's small enough)\n",
    "    df.to_csv(\"dataset.csv\", index=False)\n",
    "    mlflow.log_artifact(\"/content/dataset.csv\")\n",
    "\n",
    "# Display final accuracy\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('reddit_preprocessing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('reddit_preprocessing.csv').head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
